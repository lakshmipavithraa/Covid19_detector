{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSZJHD5MI1To"
   },
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1668,
     "status": "ok",
     "timestamp": 1622385309490,
     "user": {
      "displayName": "KLRS Biomedical",
      "photoUrl": "",
      "userId": "13462190752636494514"
     },
     "user_tz": -330
    },
    "id": "uH000j_t0eB3"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Model, Sequential, Input, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "#from keras.applications import MobileNetV2\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOsqLyqvJErM"
   },
   "source": [
    "Mounting the Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3633,
     "status": "ok",
     "timestamp": 1622385324566,
     "user": {
      "displayName": "KLRS Biomedical",
      "photoUrl": "",
      "userId": "13462190752636494514"
     },
     "user_tz": -330
    },
    "id": "_thLwEKx08Jc",
    "outputId": "cd131840-e556-4b5e-8a3a-e8e08bcfe588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBPbW4xtJK_r"
   },
   "source": [
    "Importing the dataset to local environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9611,
     "status": "ok",
     "timestamp": 1622385337914,
     "user": {
      "displayName": "KLRS Biomedical",
      "photoUrl": "",
      "userId": "13462190752636494514"
     },
     "user_tz": -330
    },
    "id": "XDSggDit1Fuj",
    "outputId": "d4384d0c-04ac-4a90-9de7-019694d2a312"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "p7zip-full is already the newest version (16.02+dfsg-6).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-460\n",
      "Use 'apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan /content/drive/MyDrive/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 folder, 1 file, 241675852 bytes (231 MiB)\n",
      "\n",
      "Extracting archive: /content/drive/MyDrive/Datasetzip/Datastcn.zip\n",
      "--\n",
      "Path = /content/drive/MyDrive/Datasetzip/Datastcn.zip\n",
      "Type = zip\n",
      "Physical Size = 241675852\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b  4% 108 - Datastcn/datasetcn/COVID/Covid (1094).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 211 - Datastcn/datasetcn/COVID/Covid (1187).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 310 - Datastcn/datasetcn/COVID/Covid (149).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 449 - Datastcn/datasetcn/COVID/Covid (274).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 548 - Datastcn/datasetcn/COVID/Covid (363).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 605 - Datastcn/datasetcn/COVID/Covid (414).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 706 - Datastcn/datasetcn/COVID/Covid (505).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 873 - Datastcn/datasetcn/COVID/Covid (656).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 998 - Datastcn/datasetcn/COVID/Covid (769).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% 1110 - Datastcn/datasetcn/COVID/Covid (87).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 1220 - Datastcn/datasetcn/COVID/Covid (969).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 1343 - Datastcn/datasetcn/non-COVID/Non-Covid (1078).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 1482 - Datastcn/datasetcn/non-COVID/Non-Covid (1202).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 1622 - Datastcn/datasetcn/non-COVID/Non-Covid (222).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 1757 - Datastcn/datasetcn/non-COVID/Non-Covid (344).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% 1884 - Datastcn/datasetcn/non-COVID/Non-Covid (459).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% 1972 - Datastcn/datasetcn/non-COVID/Non-Covid (538).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 2073 - Datastcn/datasetcn/non-COVID/Non-Covid (629).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 2195 - Datastcn/datasetcn/non-COVID/Non-Covid (739).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 2298 - Datastcn/datasetcn/non-COVID/Non-Covid (831).png\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 2404\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\bEverything is Ok\n",
      "\n",
      "Folders: 3\n",
      "Files: 2481\n",
      "Size:       242234624\n",
      "Compressed: 241675852\n"
     ]
    }
   ],
   "source": [
    "!apt-get install p7zip-full\n",
    "!7za x '/content/drive/MyDrive/Datasetzip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXlPLeOxJW7O"
   },
   "source": [
    "\n",
    "\n",
    "Creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1622385340672,
     "user": {
      "displayName": "KLRS Biomedical",
      "photoUrl": "",
      "userId": "13462190752636494514"
     },
     "user_tz": -330
    },
    "id": "bLxCDEMn1Jwm",
    "outputId": "7a06680e-9fb8-42c4-e109-1f96469dd72e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Class ID</th>\n",
       "      <th>Type of Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID/Covid (348).png</td>\n",
       "      <td>0</td>\n",
       "      <td>COVID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID/Covid (567).png</td>\n",
       "      <td>0</td>\n",
       "      <td>COVID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID/Covid (1137).png</td>\n",
       "      <td>0</td>\n",
       "      <td>COVID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COVID/Covid (1030).png</td>\n",
       "      <td>0</td>\n",
       "      <td>COVID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COVID/Covid (769).png</td>\n",
       "      <td>0</td>\n",
       "      <td>COVID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Image  Class ID Type of Disease\n",
       "0   COVID/Covid (348).png         0           COVID\n",
       "1   COVID/Covid (567).png         0           COVID\n",
       "2  COVID/Covid (1137).png         0           COVID\n",
       "3  COVID/Covid (1030).png         0           COVID\n",
       "4   COVID/Covid (769).png         0           COVID"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = []\n",
    "type_of_disease =['COVID', 'non-COVID']\n",
    "data_directory = '/content/Datastcn/datasetcn'\n",
    "train_directory = os.path.join(data_directory)\n",
    "\n",
    "for id, td in enumerate(type_of_disease):\n",
    "    for file in os.listdir(os.path.join(train_directory, td)):\n",
    "        data_train.append(['{}/{}'.format(td, file), id, td])\n",
    "        \n",
    "train = pd.DataFrame(data_train, columns=['Image', 'Class ID','Type of Disease'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1622385343667,
     "user": {
      "displayName": "KLRS Biomedical",
      "photoUrl": "",
      "userId": "13462190752636494514"
     },
     "user_tz": -330
    },
    "id": "KBO2eA8z3_nE",
    "outputId": "5edf8328-8562-4e6f-ba97-3f9f321eb16d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Class ID</th>\n",
       "      <th>Type of Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID/Covid (520).png</td>\n",
       "      <td>0</td>\n",
       "      <td>COVID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID/Covid (175).png</td>\n",
       "      <td>0</td>\n",
       "      <td>COVID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non-COVID/Non-Covid (73).png</td>\n",
       "      <td>1</td>\n",
       "      <td>non-COVID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non-COVID/Non-Covid (1155).png</td>\n",
       "      <td>1</td>\n",
       "      <td>non-COVID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COVID/Covid (741).png</td>\n",
       "      <td>0</td>\n",
       "      <td>COVID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Image  Class ID Type of Disease\n",
       "0           COVID/Covid (520).png         0           COVID\n",
       "1           COVID/Covid (175).png         0           COVID\n",
       "2    non-COVID/Non-Covid (73).png         1       non-COVID\n",
       "3  non-COVID/Non-Covid (1155).png         1       non-COVID\n",
       "4           COVID/Covid (741).png         0           COVID"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "train = train.sample(frac=1, random_state=SEED)\n",
    "train.index = np.arange(len(train))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wY-rej555hQj"
   },
   "outputs": [],
   "source": [
    "def show_images(disease_type, r, c):\n",
    "    fig,ax = plt.subplots(r,c, figsize=(10,10))\n",
    "    disease_image = train['Image'][train['Type of Disease'] == disease_type].values\n",
    "    n = 0\n",
    "    print(disease_type+' images')\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            image = os.path.join(data_directory, disease_image[n])\n",
    "            ax[i, j].set_xticks([])\n",
    "            ax[i, j].set_yticks([])\n",
    "            ax[i, j].imshow(cv2.imread(image))\n",
    "            n += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1222,
     "status": "ok",
     "timestamp": 1622385352161,
     "user": {
      "displayName": "KLRS Biomedical",
      "photoUrl": "",
      "userId": "13462190752636494514"
     },
     "user_tz": -330
    },
    "id": "8Ucr4quE8jy7"
   },
   "outputs": [],
   "source": [
    "SIZE_OF_IMAGE = 150\n",
    "def read_image(imagepath):\n",
    "    return cv2.imread(os.path.join(data_directory, imagepath))\n",
    "\n",
    "def resize_image(image, image_Size):\n",
    "    return cv2.resize(image.copy(), image_Size, interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJyUgMtQJ2Jw"
   },
   "source": [
    "Reshaping all the images to 64 * 64 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11776,
     "status": "ok",
     "timestamp": 1622385364793,
     "user": {
      "displayName": "KLRS Biomedical",
      "photoUrl": "",
      "userId": "13462190752636494514"
     },
     "user_tz": -330
    },
    "id": "amh2J0at8vs6",
    "outputId": "dd073f27-294a-4232-e39a-d65e36817d76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2481it [00:09, 248.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2481, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.zeros((train.shape[0], SIZE_OF_IMAGE, SIZE_OF_IMAGE, 3))\n",
    "\n",
    "for i, file in tqdm(enumerate(train['Image'].values)):\n",
    "    image = read_image(file)\n",
    "    \n",
    "    if image is not None:\n",
    "        x_train[i] = resize_image(image,(SIZE_OF_IMAGE, SIZE_OF_IMAGE))\n",
    "        \n",
    "X_Train = x_train / 255\n",
    "\n",
    "print('Train shape: {}'.format(X_Train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1622385366269,
     "user": {
      "displayName": "KLRS Biomedical",
      "photoUrl": "",
      "userId": "13462190752636494514"
     },
     "user_tz": -330
    },
    "id": "uLtl0RVl89V7"
   },
   "outputs": [],
   "source": [
    "y_train = train['Class ID'].values\n",
    "y_train = to_categorical(y_train, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1azeQk6PKD1e"
   },
   "source": [
    "Train test split(0.8,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 755,
     "status": "ok",
     "timestamp": 1622385367021,
     "user": {
      "displayName": "KLRS Biomedical",
      "photoUrl": "",
      "userId": "13462190752636494514"
     },
     "user_tz": -330
    },
    "id": "sVq11LAYAPTc"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_Train,y_train, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1622385417767,
     "user": {
      "displayName": "KLRS Biomedical",
      "photoUrl": "",
      "userId": "13462190752636494514"
     },
     "user_tz": -330
    },
    "id": "j6OgfsqoG9Gc"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 75\n",
    "SIZE= 150\n",
    "N_ch= 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zqBDc7OKSzq"
   },
   "source": [
    "Creating the MobileNet model with imagenet weights initially and trained the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1622385418464,
     "user": {
      "displayName": "KLRS Biomedical",
      "photoUrl": "",
      "userId": "13462190752636494514"
     },
     "user_tz": -330
    },
    "id": "NDSoG1eQHBII"
   },
   "outputs": [],
   "source": [
    "def build_mobilenet():\n",
    "    mobilenet = MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "    input = Input(shape=(SIZE, SIZE, N_ch))\n",
    "    x = Conv2D(3, (3, 3), padding='same')(input)\n",
    "    \n",
    "    x = mobilenet(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    output = Dense(2,activation = 'softmax', name='root')(x)\n",
    " \n",
    "    model = Model(input,output)\n",
    "    \n",
    "    optimizer = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 79248,
     "status": "error",
     "timestamp": 1622385502171,
     "user": {
      "displayName": "KLRS Biomedical",
      "photoUrl": "",
      "userId": "13462190752636494514"
     },
     "user_tz": -330
    },
    "id": "VU41xLIDHE8R",
    "outputId": "0e5a2372-1017-4298-dee0-9ad9a3b978c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Conv1/kernel:0' shape=(3, 3, 3, 32) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'bn_Conv1/gamma:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'bn_Conv1/beta:0' shape=(32,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'expanded_conv_depthwise/depthwise_kernel:0' shape=(3, 3, 32, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'expanded_conv_depthwise_BN/gamma:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'expanded_conv_depthwise_BN/beta:0' shape=(32,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'expanded_conv_project/kernel:0' shape=(1, 1, 32, 16) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_2), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'expanded_conv_project_BN/gamma:0' shape=(16,) dtype=float32>\n",
      "  <tf.Variable 'expanded_conv_project_BN/beta:0' shape=(16,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_2), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_1_expand/kernel:0' shape=(1, 1, 16, 96) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_3), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_1_expand_BN/gamma:0' shape=(96,) dtype=float32>\n",
      "  <tf.Variable 'block_1_expand_BN/beta:0' shape=(96,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_1_depthwise/depthwise_kernel:0' shape=(3, 3, 96, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_4), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_1_depthwise_BN/gamma:0' shape=(96,) dtype=float32>\n",
      "  <tf.Variable 'block_1_depthwise_BN/beta:0' shape=(96,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_3), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_1_project/kernel:0' shape=(1, 1, 96, 24) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_5), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_1_project_BN/gamma:0' shape=(24,) dtype=float32>\n",
      "  <tf.Variable 'block_1_project_BN/beta:0' shape=(24,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_4), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_2_expand/kernel:0' shape=(1, 1, 24, 144) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_6), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_2_expand_BN/gamma:0' shape=(144,) dtype=float32>\n",
      "  <tf.Variable 'block_2_expand_BN/beta:0' shape=(144,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_2), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_2_depthwise/depthwise_kernel:0' shape=(3, 3, 144, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_7), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_2_depthwise_BN/gamma:0' shape=(144,) dtype=float32>\n",
      "  <tf.Variable 'block_2_depthwise_BN/beta:0' shape=(144,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_5), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_2_project/kernel:0' shape=(1, 1, 144, 24) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_8), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_2_project_BN/gamma:0' shape=(24,) dtype=float32>\n",
      "  <tf.Variable 'block_2_project_BN/beta:0' shape=(24,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_6), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_3_expand/kernel:0' shape=(1, 1, 24, 144) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_9), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_3_expand_BN/gamma:0' shape=(144,) dtype=float32>\n",
      "  <tf.Variable 'block_3_expand_BN/beta:0' shape=(144,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_3), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_3_depthwise/depthwise_kernel:0' shape=(3, 3, 144, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_10), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_3_depthwise_BN/gamma:0' shape=(144,) dtype=float32>\n",
      "  <tf.Variable 'block_3_depthwise_BN/beta:0' shape=(144,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_7), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_3_project/kernel:0' shape=(1, 1, 144, 32) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_11), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_3_project_BN/gamma:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'block_3_project_BN/beta:0' shape=(32,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_8), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_4_expand/kernel:0' shape=(1, 1, 32, 192) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_12), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_4_expand_BN/gamma:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_4_expand_BN/beta:0' shape=(192,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_4), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_4_depthwise/depthwise_kernel:0' shape=(3, 3, 192, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_13), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_4_depthwise_BN/gamma:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_4_depthwise_BN/beta:0' shape=(192,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_9), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_4_project/kernel:0' shape=(1, 1, 192, 32) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_14), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_4_project_BN/gamma:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'block_4_project_BN/beta:0' shape=(32,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_10), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_5_expand/kernel:0' shape=(1, 1, 32, 192) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_15), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_5_expand_BN/gamma:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_5_expand_BN/beta:0' shape=(192,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_5), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_5_depthwise/depthwise_kernel:0' shape=(3, 3, 192, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_16), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_5_depthwise_BN/gamma:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_5_depthwise_BN/beta:0' shape=(192,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_11), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_5_project/kernel:0' shape=(1, 1, 192, 32) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_17), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_5_project_BN/gamma:0' shape=(32,) dtype=float32>\n",
      "  <tf.Variable 'block_5_project_BN/beta:0' shape=(32,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_12), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_6_expand/kernel:0' shape=(1, 1, 32, 192) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_18), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_6_expand_BN/gamma:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_6_expand_BN/beta:0' shape=(192,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_6), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_6_depthwise/depthwise_kernel:0' shape=(3, 3, 192, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_19), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_6_depthwise_BN/gamma:0' shape=(192,) dtype=float32>\n",
      "  <tf.Variable 'block_6_depthwise_BN/beta:0' shape=(192,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_13), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_6_project/kernel:0' shape=(1, 1, 192, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_20), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_6_project_BN/gamma:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'block_6_project_BN/beta:0' shape=(64,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_14), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_7_expand/kernel:0' shape=(1, 1, 64, 384) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_21), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_7_expand_BN/gamma:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_7_expand_BN/beta:0' shape=(384,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_7), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_7_depthwise/depthwise_kernel:0' shape=(3, 3, 384, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_22), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_7_depthwise_BN/gamma:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_7_depthwise_BN/beta:0' shape=(384,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_15), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_7_project/kernel:0' shape=(1, 1, 384, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_23), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_7_project_BN/gamma:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'block_7_project_BN/beta:0' shape=(64,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_16), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_8_expand/kernel:0' shape=(1, 1, 64, 384) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_24), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_8_expand_BN/gamma:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_8_expand_BN/beta:0' shape=(384,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_8), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_8_depthwise/depthwise_kernel:0' shape=(3, 3, 384, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_25), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_8_depthwise_BN/gamma:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_8_depthwise_BN/beta:0' shape=(384,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_17), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_8_project/kernel:0' shape=(1, 1, 384, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_26), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_8_project_BN/gamma:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'block_8_project_BN/beta:0' shape=(64,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_18), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_9_expand/kernel:0' shape=(1, 1, 64, 384) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_27), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_9_expand_BN/gamma:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_9_expand_BN/beta:0' shape=(384,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_9), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_9_depthwise/depthwise_kernel:0' shape=(3, 3, 384, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_28), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_9_depthwise_BN/gamma:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_9_depthwise_BN/beta:0' shape=(384,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_19), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_9_project/kernel:0' shape=(1, 1, 384, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_29), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_9_project_BN/gamma:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'block_9_project_BN/beta:0' shape=(64,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_20), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_10_expand/kernel:0' shape=(1, 1, 64, 384) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_30), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_10_expand_BN/gamma:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_10_expand_BN/beta:0' shape=(384,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_10), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_10_depthwise/depthwise_kernel:0' shape=(3, 3, 384, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_31), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_10_depthwise_BN/gamma:0' shape=(384,) dtype=float32>\n",
      "  <tf.Variable 'block_10_depthwise_BN/beta:0' shape=(384,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_21), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_10_project/kernel:0' shape=(1, 1, 384, 96) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_32), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_10_project_BN/gamma:0' shape=(96,) dtype=float32>\n",
      "  <tf.Variable 'block_10_project_BN/beta:0' shape=(96,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_22), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_11_expand/kernel:0' shape=(1, 1, 96, 576) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_33), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_11_expand_BN/gamma:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_11_expand_BN/beta:0' shape=(576,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_11), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_11_depthwise/depthwise_kernel:0' shape=(3, 3, 576, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_34), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_11_depthwise_BN/gamma:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_11_depthwise_BN/beta:0' shape=(576,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_23), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_11_project/kernel:0' shape=(1, 1, 576, 96) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_35), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_11_project_BN/gamma:0' shape=(96,) dtype=float32>\n",
      "  <tf.Variable 'block_11_project_BN/beta:0' shape=(96,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_24), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_12_expand/kernel:0' shape=(1, 1, 96, 576) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_36), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_12_expand_BN/gamma:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_12_expand_BN/beta:0' shape=(576,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_12), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_12_depthwise/depthwise_kernel:0' shape=(3, 3, 576, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_37), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_12_depthwise_BN/gamma:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_12_depthwise_BN/beta:0' shape=(576,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_25), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_12_project/kernel:0' shape=(1, 1, 576, 96) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_38), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_12_project_BN/gamma:0' shape=(96,) dtype=float32>\n",
      "  <tf.Variable 'block_12_project_BN/beta:0' shape=(96,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_26), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_13_expand/kernel:0' shape=(1, 1, 96, 576) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_39), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_13_expand_BN/gamma:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_13_expand_BN/beta:0' shape=(576,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_13), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_13_depthwise/depthwise_kernel:0' shape=(3, 3, 576, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_40), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_13_depthwise_BN/gamma:0' shape=(576,) dtype=float32>\n",
      "  <tf.Variable 'block_13_depthwise_BN/beta:0' shape=(576,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_27), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_13_project/kernel:0' shape=(1, 1, 576, 160) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_41), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_13_project_BN/gamma:0' shape=(160,) dtype=float32>\n",
      "  <tf.Variable 'block_13_project_BN/beta:0' shape=(160,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_28), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_14_expand/kernel:0' shape=(1, 1, 160, 960) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_42), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_14_expand_BN/gamma:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_14_expand_BN/beta:0' shape=(960,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_14), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_14_depthwise/depthwise_kernel:0' shape=(3, 3, 960, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_43), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_14_depthwise_BN/gamma:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_14_depthwise_BN/beta:0' shape=(960,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_29), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_14_project/kernel:0' shape=(1, 1, 960, 160) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_44), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_14_project_BN/gamma:0' shape=(160,) dtype=float32>\n",
      "  <tf.Variable 'block_14_project_BN/beta:0' shape=(160,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_30), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_15_expand/kernel:0' shape=(1, 1, 160, 960) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_45), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_15_expand_BN/gamma:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_15_expand_BN/beta:0' shape=(960,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_15), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_15_depthwise/depthwise_kernel:0' shape=(3, 3, 960, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_46), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_15_depthwise_BN/gamma:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_15_depthwise_BN/beta:0' shape=(960,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_31), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_15_project/kernel:0' shape=(1, 1, 960, 160) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_47), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_15_project_BN/gamma:0' shape=(160,) dtype=float32>\n",
      "  <tf.Variable 'block_15_project_BN/beta:0' shape=(160,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_32), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_16_expand/kernel:0' shape=(1, 1, 160, 960) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_48), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_16_expand_BN/gamma:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_16_expand_BN/beta:0' shape=(960,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.depthwise_conv2d_16), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_16_depthwise/depthwise_kernel:0' shape=(3, 3, 960, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_49), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_16_depthwise_BN/gamma:0' shape=(960,) dtype=float32>\n",
      "  <tf.Variable 'block_16_depthwise_BN/beta:0' shape=(960,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_33), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_16_project/kernel:0' shape=(1, 1, 960, 320) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_50), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'block_16_project_BN/gamma:0' shape=(320,) dtype=float32>\n",
      "  <tf.Variable 'block_16_project_BN/beta:0' shape=(320,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.nn.convolution_34), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Conv_1/kernel:0' shape=(1, 1, 320, 1280) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_51), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Conv_1_bn/gamma:0' shape=(1280,) dtype=float32>\n",
      "  <tf.Variable 'Conv_1_bn/beta:0' shape=(1280,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 150, 150, 3)  84          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution (TFOpLambda)  (None, 75, 75, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 75, 75, 32), 0           tf.nn.convolution[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6 (TFOpLambda)        (None, 75, 75, 32)   0           tf.compat.v1.nn.fused_batch_norm[\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.depthwise_conv2 (None, 75, 75, 32)   0           tf.nn.relu6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 75, 75, 32), 0           tf.compat.v1.nn.depthwise_conv2d[\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_1 (TFOpLambda)      (None, 75, 75, 32)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_1 (TFOpLambda (None, 75, 75, 16)   0           tf.nn.relu6_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 75, 75, 16), 0           tf.nn.convolution_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_2 (TFOpLambda (None, 75, 75, 96)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 75, 75, 96), 0           tf.nn.convolution_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_2 (TFOpLambda)      (None, 75, 75, 96)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad (TFOpLambda)   (None, 76, 76, 96)   0           tf.nn.relu6_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.depthwise_conv2 (None, 37, 37, 96)   0           tf.compat.v1.pad[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 37, 37, 96), 0           tf.compat.v1.nn.depthwise_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_3 (TFOpLambda)      (None, 37, 37, 96)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_3 (TFOpLambda (None, 37, 37, 24)   0           tf.nn.relu6_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 37, 37, 24), 0           tf.nn.convolution_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_4 (TFOpLambda (None, 37, 37, 144)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 37, 37, 144) 0           tf.nn.convolution_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_4 (TFOpLambda)      (None, 37, 37, 144)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.depthwise_conv2 (None, 37, 37, 144)  0           tf.nn.relu6_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 37, 37, 144) 0           tf.compat.v1.nn.depthwise_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_5 (TFOpLambda)      (None, 37, 37, 144)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_5 (TFOpLambda (None, 37, 37, 24)   0           tf.nn.relu6_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 37, 37, 24), 0           tf.nn.convolution_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 37, 37, 24)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_6 (TFOpLambda (None, 37, 37, 144)  0           tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 37, 37, 144) 0           tf.nn.convolution_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_6 (TFOpLambda)      (None, 37, 37, 144)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_1 (TFOpLambda) (None, 38, 38, 144)  0           tf.nn.relu6_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.depthwise_conv2 (None, 18, 18, 144)  0           tf.compat.v1.pad_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 18, 18, 144) 0           tf.compat.v1.nn.depthwise_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_7 (TFOpLambda)      (None, 18, 18, 144)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_7 (TFOpLambda (None, 18, 18, 32)   0           tf.nn.relu6_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 18, 18, 32), 0           tf.nn.convolution_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_8 (TFOpLambda (None, 18, 18, 192)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 18, 18, 192) 0           tf.nn.convolution_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_8 (TFOpLambda)      (None, 18, 18, 192)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.depthwise_conv2 (None, 18, 18, 192)  0           tf.nn.relu6_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 18, 18, 192) 0           tf.compat.v1.nn.depthwise_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_9 (TFOpLambda)      (None, 18, 18, 192)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_9 (TFOpLambda (None, 18, 18, 32)   0           tf.nn.relu6_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 18, 18, 32), 0           tf.nn.convolution_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 18, 18, 32)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_10 (TFOpLambd (None, 18, 18, 192)  0           tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 18, 18, 192) 0           tf.nn.convolution_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_10 (TFOpLambda)     (None, 18, 18, 192)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.depthwise_conv2 (None, 18, 18, 192)  0           tf.nn.relu6_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 18, 18, 192) 0           tf.compat.v1.nn.depthwise_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_11 (TFOpLambda)     (None, 18, 18, 192)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_11 (TFOpLambd (None, 18, 18, 32)   0           tf.nn.relu6_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 18, 18, 32), 0           tf.nn.convolution_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 18, 18, 32)   0           tf.__operators__.add_1[0][0]     \n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_12 (TFOpLambd (None, 18, 18, 192)  0           tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 18, 18, 192) 0           tf.nn.convolution_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_12 (TFOpLambda)     (None, 18, 18, 192)  0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_2 (TFOpLambda) (None, 19, 19, 192)  0           tf.nn.relu6_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.depthwise_conv2 (None, 9, 9, 192)    0           tf.compat.v1.pad_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 192),  0           tf.compat.v1.nn.depthwise_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_13 (TFOpLambda)     (None, 9, 9, 192)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_13 (TFOpLambd (None, 9, 9, 64)     0           tf.nn.relu6_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 64), ( 0           tf.nn.convolution_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_14 (TFOpLambd (None, 9, 9, 384)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 384),  0           tf.nn.convolution_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_14 (TFOpLambda)     (None, 9, 9, 384)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.depthwise_conv2 (None, 9, 9, 384)    0           tf.nn.relu6_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 384),  0           tf.compat.v1.nn.depthwise_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_15 (TFOpLambda)     (None, 9, 9, 384)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_15 (TFOpLambd (None, 9, 9, 64)     0           tf.nn.relu6_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 64), ( 0           tf.nn.convolution_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 9, 9, 64)     0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_16 (TFOpLambd (None, 9, 9, 384)    0           tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 384),  0           tf.nn.convolution_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_16 (TFOpLambda)     (None, 9, 9, 384)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.depthwise_conv2 (None, 9, 9, 384)    0           tf.nn.relu6_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 384),  0           tf.compat.v1.nn.depthwise_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_17 (TFOpLambda)     (None, 9, 9, 384)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_17 (TFOpLambd (None, 9, 9, 64)     0           tf.nn.relu6_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 64), ( 0           tf.nn.convolution_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_4 (TFOpLam (None, 9, 9, 64)     0           tf.__operators__.add_3[0][0]     \n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_18 (TFOpLambd (None, 9, 9, 384)    0           tf.__operators__.add_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 384),  0           tf.nn.convolution_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_18 (TFOpLambda)     (None, 9, 9, 384)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.depthwise_conv2 (None, 9, 9, 384)    0           tf.nn.relu6_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 384),  0           tf.compat.v1.nn.depthwise_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_19 (TFOpLambda)     (None, 9, 9, 384)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_19 (TFOpLambd (None, 9, 9, 64)     0           tf.nn.relu6_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 64), ( 0           tf.nn.convolution_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_5 (TFOpLam (None, 9, 9, 64)     0           tf.__operators__.add_4[0][0]     \n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_20 (TFOpLambd (None, 9, 9, 384)    0           tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 384),  0           tf.nn.convolution_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_20 (TFOpLambda)     (None, 9, 9, 384)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.depthwise_conv2 (None, 9, 9, 384)    0           tf.nn.relu6_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 384),  0           tf.compat.v1.nn.depthwise_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_21 (TFOpLambda)     (None, 9, 9, 384)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_21 (TFOpLambd (None, 9, 9, 96)     0           tf.nn.relu6_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 96), ( 0           tf.nn.convolution_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_22 (TFOpLambd (None, 9, 9, 576)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 576),  0           tf.nn.convolution_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_22 (TFOpLambda)     (None, 9, 9, 576)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.depthwise_conv2 (None, 9, 9, 576)    0           tf.nn.relu6_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 576),  0           tf.compat.v1.nn.depthwise_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_23 (TFOpLambda)     (None, 9, 9, 576)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_23 (TFOpLambd (None, 9, 9, 96)     0           tf.nn.relu6_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 96), ( 0           tf.nn.convolution_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_6 (TFOpLam (None, 9, 9, 96)     0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_24 (TFOpLambd (None, 9, 9, 576)    0           tf.__operators__.add_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 576),  0           tf.nn.convolution_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_24 (TFOpLambda)     (None, 9, 9, 576)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.depthwise_conv2 (None, 9, 9, 576)    0           tf.nn.relu6_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 576),  0           tf.compat.v1.nn.depthwise_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_25 (TFOpLambda)     (None, 9, 9, 576)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_25 (TFOpLambd (None, 9, 9, 96)     0           tf.nn.relu6_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 96), ( 0           tf.nn.convolution_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_7 (TFOpLam (None, 9, 9, 96)     0           tf.__operators__.add_6[0][0]     \n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_26 (TFOpLambd (None, 9, 9, 576)    0           tf.__operators__.add_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 9, 9, 576),  0           tf.nn.convolution_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_26 (TFOpLambda)     (None, 9, 9, 576)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_3 (TFOpLambda) (None, 10, 10, 576)  0           tf.nn.relu6_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.depthwise_conv2 (None, 4, 4, 576)    0           tf.compat.v1.pad_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 4, 4, 576),  0           tf.compat.v1.nn.depthwise_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_27 (TFOpLambda)     (None, 4, 4, 576)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_27 (TFOpLambd (None, 4, 4, 160)    0           tf.nn.relu6_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 4, 4, 160),  0           tf.nn.convolution_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_28 (TFOpLambd (None, 4, 4, 960)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 4, 4, 960),  0           tf.nn.convolution_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_28 (TFOpLambda)     (None, 4, 4, 960)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.depthwise_conv2 (None, 4, 4, 960)    0           tf.nn.relu6_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 4, 4, 960),  0           tf.compat.v1.nn.depthwise_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_29 (TFOpLambda)     (None, 4, 4, 960)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_29 (TFOpLambd (None, 4, 4, 160)    0           tf.nn.relu6_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 4, 4, 160),  0           tf.nn.convolution_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_8 (TFOpLam (None, 4, 4, 160)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_30 (TFOpLambd (None, 4, 4, 960)    0           tf.__operators__.add_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 4, 4, 960),  0           tf.nn.convolution_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_30 (TFOpLambda)     (None, 4, 4, 960)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.depthwise_conv2 (None, 4, 4, 960)    0           tf.nn.relu6_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 4, 4, 960),  0           tf.compat.v1.nn.depthwise_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_31 (TFOpLambda)     (None, 4, 4, 960)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_31 (TFOpLambd (None, 4, 4, 160)    0           tf.nn.relu6_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 4, 4, 160),  0           tf.nn.convolution_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_9 (TFOpLam (None, 4, 4, 160)    0           tf.__operators__.add_8[0][0]     \n",
      "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_32 (TFOpLambd (None, 4, 4, 960)    0           tf.__operators__.add_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 4, 4, 960),  0           tf.nn.convolution_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_32 (TFOpLambda)     (None, 4, 4, 960)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.depthwise_conv2 (None, 4, 4, 960)    0           tf.nn.relu6_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 4, 4, 960),  0           tf.compat.v1.nn.depthwise_conv2d_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_33 (TFOpLambda)     (None, 4, 4, 960)    0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_33 (TFOpLambd (None, 4, 4, 320)    0           tf.nn.relu6_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 4, 4, 320),  0           tf.nn.convolution_33[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.convolution_34 (TFOpLambd (None, 4, 4, 1280)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.fused_batch_nor ((None, 4, 4, 1280), 0           tf.nn.convolution_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu6_34 (TFOpLambda)     (None, 4, 4, 1280)   0           tf.compat.v1.nn.fused_batch_norm_\n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1280)         0           tf.nn.relu6_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1280)         5120        global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1280)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          327936      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "root (Dense)                    (None, 2)            514         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 334,678\n",
      "Trainable params: 331,606\n",
      "Non-trainable params: 3,072\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "31/31 - 69s - loss: 1.2352 - accuracy: 0.4879 - val_loss: 0.8677 - val_accuracy: 0.4668\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.86772, saving model to /content/drive/MyDrive/Colab Notebooks/mobilenetv23005_best.h5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/node.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(self, make_node_key, node_conversion_map)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m       \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_json_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/json_utils.py\u001b[0m in \u001b[0;36mget_json_type\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not JSON Serializable:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: ('Not JSON Serializable:', <tf.Variable 'Conv1/kernel:0' shape=(3, 3, 3, 32) dtype=float32, numpy=\narray([[[[-1.71659231e-01, -3.33731920e-01,  5.30122258e-02,\n          -5.93232973e-21,  2.08742931e-01, -1.20433941e-01,\n           1.75700430e-02, -3.10708203e-22, -9.62498877e-03,\n           1.90229788e-01, -3.67278278e-01,  3.95997976e-22,\n          -2.36236629e-22,  3.36706383e-22,  8.83555040e-02,\n          -7.75416642e-02,  3.95842289e-05, -3.63377742e-02,\n           5.99925742e-02,  5.53736472e-21, -4.68022423e-04,\n          -1.23387486e-01, -1.34351701e-01,  8.75968020e-03,\n          -2.47503355e-01,  1.58492010e-02, -2.43145856e-04,\n          -1.09811597e-01,  5.55126644e-22, -2.03368161e-03,\n           2.83311605e-01,  7.66634047e-02],\n         [-3.18941772e-01, -6.09864295e-01, -1.70770675e-01,\n          -6.76705635e-21, -5.82342505e-01, -2.56068230e-01,\n          -4.18974347e-02,  1.32427304e-22,  2.00757684e-04,\n           3.29488933e-01, -4.01886106e-01,  3.63034420e-22,\n           1.64733595e-22,  1.97648923e-22,  9.94425565e-02,\n          -1.17755957e-01,  5.50664954e-05, -5.31860851e-02,\n          -2.15648204e-01,  3.16011650e-21,  8.09127018e-02,\n           7.85512850e-02, -2.84253448e-01,  1.42605125e-03,\n          -3.66104782e-01,  5.07289954e-02, -3.62347142e-04,\n          -1.89613834e-01, -1.61162945e-22,  2.00382178e-03,\n           4.86412019e-01,  2.47807782e-02],\n         [-1.06408961e-01, -1.84493005e-01,  9.77970883e-02,\n          -8.81519674e-22,  3.80435824e-01, -6.83505908e-02,\n           8.65232944e-02,  1.86135438e-23,  1.71185266e-02,\n           7.75882900e-02, -1.56868771e-01,  3.51591948e-22,\n           4.44115563e-22,  8.28426129e-23,  3.24417278e-03,\n          -1.86904948e-02,  3.05484100e-05, -1.91261359e-02,\n          -3.72639090e-01,  4.24975389e-21, -4.80259806e-02,\n           5.32024391e-02, -8.11035931e-02,  5.26270643e-02,\n          -1.33920342e-01,  9.19177756e-03, -6.44940825e-04,\n          -7.19209313e-02, -4.44417880e-22,  1.16088893e-02,\n           1.72385767e-01, -4.47827466e-02]],\n\n        [[-2.87314355e-01,  3.51008356e-01, -1.17478400e-01,\n          -4.61353767e-21,  1.38406008e-01, -1.70154870e-02,\n          -5.68470620e-02, -4.43750592e-22,  8.07509869e-02,\n           3.19523960e-01,  1.30609721e-02,  3.35785776e-22,\n           2.05983384e-22,  1.89247567e-22,  6.08652234e-02,\n           1.39344618e-01,  3.88040426e-05, -1.12312555e-01,\n          -5.10888137e-02,  3.90697840e-21, -4.68926504e-02,\n          -5.18504858e-01,  2.69424438e-01,  6.47785142e-02,\n          -2.31717825e-01,  4.06695381e-02, -2.39890942e-04,\n           3.87762189e-01,  6.68873470e-22, -4.99280617e-02,\n           7.80958533e-02,  1.25117842e-02],\n         [-4.70178574e-01,  6.41047657e-01,  1.26409885e-02,\n          -5.16069543e-21, -5.43751836e-01, -3.93946394e-02,\n          -8.81260261e-02, -2.57652877e-22,  1.85136840e-01,\n           5.26121736e-01,  2.44704559e-02,  2.41477189e-22,\n           5.13344027e-22,  3.16681407e-22,  2.63062596e-01,\n           2.03965262e-01,  5.34717110e-05, -2.17281029e-01,\n          -6.19981587e-02,  1.58240941e-22,  6.70444518e-02,\n           4.09571230e-01,  3.79201621e-01, -1.18417814e-02,\n          -3.75138670e-01,  7.55842403e-02, -3.58388264e-04,\n           6.82722807e-01, -1.08337802e-22, -8.74376483e-03,\n          -1.15310679e-04,  1.64284706e-01],\n         [-1.31381691e-01,  2.14141354e-01,  1.04324631e-01,\n           6.33635041e-22,  4.32741165e-01, -1.09126009e-02,\n          -1.82016846e-02, -3.04778746e-22,  5.29873930e-02,\n           1.40438825e-01,  5.16454205e-02,  2.71163250e-22,\n           4.81404526e-22,  3.10725015e-22,  3.39648761e-02,\n           4.40633148e-02,  2.88985811e-05, -5.88206127e-02,\n          -3.07638168e-01,  2.91914926e-21,  3.03943339e-03,\n           1.23323597e-01,  5.51084056e-02,  1.33606374e-01,\n          -1.14002161e-01,  1.74121037e-02, -6.40736660e-04,\n           2.47402862e-01, -4.02265066e-22,  7.09590018e-02,\n          -5.51886968e-02,  4.61399741e-02]],\n\n        [[-7.13241175e-02, -5.44480048e-02, -1.53101355e-01,\n          -3.46754759e-21, -2.92075332e-02, -4.15141927e-03,\n           7.10874517e-03,  1.25174631e-22, -4.28606980e-02,\n           1.30710959e-01,  6.60812110e-02,  3.21970007e-22,\n           5.30186725e-22, -1.40879198e-22,  2.94084921e-02,\n           2.19062008e-02,  3.87144682e-05,  1.24649018e-01,\n           1.65672775e-03,  7.01061015e-22, -6.85967505e-02,\n          -4.42052186e-01, -1.66539565e-01,  1.29611045e-01,\n          -2.07900349e-02,  7.91681744e-03, -2.40658235e-04,\n          -2.82942057e-01,  4.92878476e-22,  1.51173487e-01,\n          -2.99598724e-02, -1.59751475e-01],\n         [-1.04590982e-01, -8.46857205e-02,  9.30620581e-02,\n          -3.85997249e-21,  7.01299077e-03, -1.15499017e-03,\n           2.28845645e-02,  7.60947535e-23, -7.71953315e-02,\n           1.78015113e-01, -1.12577220e-02,  1.51740866e-22,\n           6.90820363e-22,  3.41281321e-22,  2.01023489e-01,\n           1.73829962e-02,  5.32969316e-05,  2.43513107e-01,\n           2.25045353e-01, -4.07146699e-21,  5.84838390e-02,\n           2.94529080e-01, -1.29661292e-01, -5.71099157e-03,\n          -8.74263514e-03,  3.28077935e-02, -3.31327232e-04,\n          -4.78810728e-01, -1.77089034e-23, -1.69841900e-01,\n          -7.23650381e-02,  6.80657774e-02],\n         [-5.72547950e-02, -3.57813686e-02,  5.39425388e-02,\n           1.01598721e-21,  3.40574384e-02,  1.04662832e-02,\n           5.95801212e-02,  1.13053386e-22, -2.32412457e-03,\n           3.70449498e-02,  8.42491817e-03,  2.44916244e-22,\n           8.29260933e-22,  4.30840132e-22,  2.45401021e-02,\n           1.38844494e-02,  2.78819298e-05,  6.57479838e-02,\n          -2.71652520e-01,  9.32158738e-22,  4.10489365e-02,\n           1.44604623e-01,  1.91524066e-02,  2.18437687e-01,\n          -3.21538821e-02,  4.63133771e-03, -6.14255900e-04,\n          -1.89390138e-01, -2.97987398e-22,  3.50938737e-02,\n          -1.20920930e-02,  4.00171317e-02]]],\n\n\n       [[[ 2.85172611e-01, -4.66781408e-01,  1.21226743e-01,\n          -6.75641286e-21,  1.26153544e-01, -3.19687217e-01,\n          -2.05815881e-02, -5.95099956e-22,  1.86711565e-01,\n          -2.01214001e-01, -8.15609191e-03,  5.38772056e-22,\n          -2.10281966e-23,  5.45086376e-22,  6.33758679e-02,\n          -1.66991681e-01,  4.00609460e-05, -5.95138147e-02,\n           4.17197123e-03,  7.88645871e-21, -2.25693025e-02,\n          -4.09983039e-01,  8.08365121e-02, -6.15043566e-02,\n          -1.48460045e-01, -1.35266587e-01, -2.57411273e-04,\n           2.52952557e-02,  3.40634683e-22, -4.70980853e-01,\n          -1.97121538e-02,  1.58776045e-01],\n         [ 5.22245169e-01, -7.74718702e-01, -1.03791185e-01,\n          -7.48817609e-21, -4.88066822e-01, -5.08516729e-01,\n          -6.87498525e-02, -5.89509721e-22,  2.95846373e-01,\n          -3.49212021e-01, -7.43358675e-03,  4.21490123e-22,\n           4.70657943e-22,  4.22498300e-22,  8.62299651e-02,\n          -2.54522473e-01,  5.60653571e-05, -7.33832195e-02,\n          -8.60270858e-02,  5.67678949e-21,  5.62448874e-02,\n           3.09744745e-01,  4.14053917e-01,  1.73171610e-02,\n          -1.73137128e-01, -2.80544072e-01, -3.75996431e-04,\n           1.62907485e-02, -1.88705424e-22,  2.44924217e-01,\n           1.82298268e-03, -1.08400427e-01],\n         [ 1.60939455e-01, -2.00135484e-01, -1.91477668e-02,\n          -2.64173922e-21,  3.77884656e-01, -1.45450443e-01,\n          -2.31361631e-02, -4.98238388e-22,  7.54485354e-02,\n          -8.77666771e-02, -2.72841360e-02,  5.27507526e-22,\n           2.87445212e-22,  2.83338819e-22,  2.84198094e-02,\n          -7.07984418e-02,  3.22252235e-05, -2.63583586e-02,\n          -2.58129507e-01,  3.97605162e-21, -3.02919410e-02,\n           1.21599890e-01,  1.29800081e-01, -8.01057294e-02,\n          -6.48759529e-02, -6.94882795e-02, -6.56989636e-04,\n           3.28051820e-02, -5.15508156e-22,  2.17810869e-01,\n           3.88336740e-02, -5.97701780e-02]],\n\n        [[ 3.87341738e-01,  3.87497842e-01, -9.80749726e-02,\n          -5.17903396e-21,  1.24578401e-01,  1.88840309e-03,\n          -2.52023727e-01, -1.07139418e-21,  2.18721405e-01,\n          -2.36569211e-01,  2.11741570e-02,  4.31771064e-22,\n          -2.59537348e-24,  7.22557260e-22,  2.71504879e-01,\n           2.92931616e-01,  3.91017820e-05, -1.48509949e-01,\n          -6.20114207e-02,  5.94595277e-21, -6.28862977e-02,\n          -6.11441255e-01, -2.43088663e-01, -2.32522693e-02,\n          -1.27775833e-01,  3.04467548e-02, -2.59789231e-04,\n           4.49484080e-01,  4.97331640e-22, -4.60955739e-01,\n           1.73044223e-02,  6.84555620e-02],\n         [ 6.91597521e-01,  6.57902241e-01,  9.73145738e-02,\n          -5.28414082e-21, -6.14119649e-01,  1.24160377e-02,\n          -2.50092238e-01, -1.00353275e-21,  3.71131808e-01,\n          -4.49236393e-01,  1.09708365e-02,  3.22428985e-22,\n           1.40751971e-22,  8.04534271e-22,  3.75909477e-01,\n           5.13077021e-01,  5.44164250e-05, -3.04835290e-01,\n          -1.38802871e-01,  1.95102584e-21,  4.64400873e-02,\n           4.84742433e-01, -5.33343732e-01, -1.62434147e-03,\n          -1.99492723e-01,  6.13993630e-02, -3.79001547e-04,\n           7.41868556e-01, -8.45936254e-23,  1.71518534e-01,\n          -7.20013529e-02, -1.11293845e-01],\n         [ 2.01059088e-01,  1.76642910e-01,  8.02056398e-03,\n          -9.39462808e-22,  4.96743679e-01,  2.67602596e-03,\n          -2.80774295e-01, -8.48839073e-22,  1.01323023e-01,\n          -1.04164392e-01,  2.47893278e-02,  4.71371730e-22,\n          -5.93821673e-23,  5.33745813e-22,  1.27857119e-01,\n           1.29921854e-01,  3.02072058e-05, -7.62646645e-02,\n          -1.91035971e-01,  1.47662614e-21,  1.58005096e-02,\n           1.16211362e-01, -1.53215021e-01, -2.61576604e-02,\n          -6.74823746e-02,  9.62385256e-03, -6.57810771e-04,\n           2.20218241e-01, -3.19080352e-22,  3.03777575e-01,\n           1.73404478e-02, -4.18657474e-02]],\n\n        [[ 1.75250113e-01,  9.96352211e-02, -2.17413306e-01,\n          -5.37611216e-21,  4.59666438e-02, -1.56036187e-02,\n          -1.98591612e-02, -1.92631263e-22,  1.30595729e-01,\n          -1.16602801e-01,  8.72978289e-03,  4.64697638e-22,\n           6.64051296e-22,  1.00259753e-22,  6.36651292e-02,\n          -3.20460163e-02,  3.86894681e-05,  2.17387348e-01,\n           4.66108322e-04,  3.80994301e-21, -8.92490745e-02,\n          -1.69830129e-01,  1.86291739e-01,  4.49458919e-02,\n           2.24591512e-02, -2.16702428e-02, -2.64769798e-04,\n          -4.56495821e-01,  3.23025818e-22, -1.24534540e-01,\n          -3.41693312e-02,  2.39991527e-02],\n         [ 2.25760370e-01,  1.54949903e-01,  1.84233695e-01,\n          -5.05620410e-21, -1.31883770e-01, -1.33964298e-02,\n          -1.57751236e-02, -3.70011484e-22,  1.94140896e-01,\n          -1.68711200e-01, -2.13335417e-02,  3.95136893e-22,\n           1.15517025e-21,  4.35371248e-22,  1.17296120e-02,\n          -3.26589383e-02,  5.35929939e-05,  4.07269001e-01,\n           8.09750259e-02, -1.71447399e-21,  3.33166532e-02,\n           1.34170264e-01,  1.68289483e-01,  1.64807606e-02,\n          -1.81587972e-02, -3.21071781e-02, -3.53615935e-04,\n          -7.16512680e-01,  6.92674338e-23, -6.01313077e-03,\n           1.79661124e-03, -2.85612280e-03],\n         [ 6.99371397e-02,  3.71139944e-02,  4.12876718e-02,\n          -1.08841560e-21,  8.02633613e-02,  1.31739341e-02,\n          -3.30819488e-02, -4.26323758e-22,  5.49282879e-02,\n          -3.45131308e-02,  1.57861374e-02,  4.35426279e-22,\n           8.51572141e-22,  2.11475736e-22,  2.05195062e-02,\n           1.59445889e-02,  2.87573366e-05,  1.15359500e-01,\n          -1.47560090e-01,  1.25288641e-21,  4.66573052e-02,\n           3.75384502e-02,  1.97264720e-02,  6.03193864e-02,\n          -1.99527182e-02, -5.51127223e-03, -6.35929755e-04,\n          -2.32582122e-01, -2.07820597e-22,  1.45871952e-01,\n           4.55161184e-02,  4.70330529e-02]]],\n\n\n       [[[-9.97005925e-02, -2.93488447e-02,  1.59716457e-01,\n          -4.57298562e-21, -3.80734447e-03, -1.93656892e-01,\n          -1.96195394e-02,  1.50415422e-23, -1.75130889e-01,\n          -6.43224514e-04,  7.35929757e-02,  5.21648094e-22,\n           2.66177144e-22,  1.84979161e-22, -4.31124158e-02,\n          -1.27358034e-01,  3.98856282e-05, -5.35858795e-02,\n           2.02303287e-02,  5.88748426e-21,  1.22341560e-03,\n          -2.59160876e-01,  6.02254234e-02, -1.02874666e-01,\n          -1.56587102e-02, -3.04274946e-01, -2.61499459e-04,\n          -1.55204520e-01,  2.36881980e-22, -4.21787679e-01,\n          -5.48078343e-02,  1.27067879e-01],\n         [-1.66218802e-01, -1.45061156e-02, -8.51615220e-02,\n          -5.48453664e-21, -9.06879604e-02, -2.35105366e-01,\n          -2.03693341e-02,  1.17546396e-22, -3.34907681e-01,\n           2.14026552e-02, -1.36370184e-02,  4.80906672e-22,\n           5.99923392e-22,  1.13800847e-22, -2.21041106e-02,\n          -1.67737678e-01,  5.62142341e-05, -6.26927465e-02,\n           1.15618229e-01,  3.30852050e-21,  2.92944014e-02,\n           1.82802349e-01, -1.34657145e-01,  7.60557577e-02,\n          -3.33149964e-03, -4.80297446e-01, -3.87676555e-04,\n          -2.70250082e-01, -2.21948755e-22,  2.08523810e-01,\n          -4.84536169e-03, -7.65069155e-03],\n         [-5.64294979e-02, -1.39049627e-02, -7.07797408e-02,\n          -2.11593164e-21,  9.70602781e-02, -7.46867284e-02,\n           2.67708022e-02,  1.34313982e-22, -1.13574006e-01,\n          -1.24347594e-03, -1.69572085e-02,  4.51941316e-22,\n           2.98691062e-22, -4.05920180e-22,  1.51855014e-02,\n          -3.62584107e-02,  3.27394519e-05, -1.18512157e-02,\n          -1.31693915e-01,  1.16023228e-21, -1.30534060e-02,\n           7.47819990e-02, -5.95608167e-02, -1.85731784e-01,\n           2.52844742e-03, -1.27434418e-01, -6.77550561e-04,\n          -9.88538265e-02, -5.68250917e-22,  1.95529610e-01,\n          -2.80292728e-03, -1.52085572e-01]],\n\n        [[ 5.33203734e-03,  1.34540394e-01,  3.21403262e-03,\n          -3.77017008e-21,  5.94239905e-02,  5.62200360e-02,\n          -8.66190903e-03, -5.41155653e-22, -3.40149581e-01,\n           1.05262510e-02, -1.18222823e-02,  3.75745253e-22,\n           6.54014915e-22,  1.01238647e-22,  1.20204603e-02,\n           2.12544292e-01,  3.88772241e-05, -8.04151744e-02,\n           3.27666998e-02,  4.09139848e-21, -4.18575145e-02,\n          -1.41649812e-01, -2.75274664e-02, -6.30021393e-02,\n          -1.23056835e-02,  5.76790757e-02, -2.66849995e-04,\n           1.73668101e-01,  3.87951999e-22, -3.71757209e-01,\n           5.39395120e-03, -3.98359867e-03],\n         [-2.58152336e-02,  1.85409024e-01,  5.54025732e-02,\n          -3.72844916e-21, -1.53836429e-01,  7.72569105e-02,\n          -7.24380165e-02, -4.66109560e-22, -5.64845920e-01,\n           5.58318011e-02, -1.54055031e-02,  2.97017137e-22,\n           7.45388081e-22,  1.81958328e-22, -4.19078469e-02,\n           2.88533330e-01,  5.46408628e-05, -1.36487991e-01,\n           1.42975734e-03,  7.14380420e-22,  1.58474650e-02,\n           1.44700661e-01,  1.59496695e-01,  7.65543059e-02,\n           8.35181121e-03,  1.21500485e-01, -3.91204987e-04,\n           2.08372265e-01, -3.59457989e-22,  1.55389652e-01,\n           4.71843891e-02,  4.84885238e-02],\n         [ 1.91994663e-03,  7.66409039e-02, -5.63072078e-02,\n          -3.11575773e-22,  9.76094007e-02,  1.56323258e-02,\n          -2.37357598e-02, -3.71001233e-22, -1.56747624e-01,\n           1.20678693e-02,  7.79418182e-03,  2.96126747e-22,\n           3.47260534e-22, -2.49029882e-22, -8.42827931e-03,\n           8.35052058e-02,  3.09280367e-05, -3.61602530e-02,\n          -4.53046560e-02, -2.44103427e-22,  2.11121719e-02,\n          -1.02299070e-02,  9.31130797e-02, -1.26273841e-01,\n          -5.91338193e-03,  4.07350324e-02, -6.80822472e-04,\n           1.04001425e-01, -6.56476414e-22,  2.37940669e-01,\n          -5.06443344e-03, -4.40830505e-03]],\n\n        [[-9.05388594e-02, -1.05114892e-01, -1.35785878e-01,\n          -4.00610437e-21,  5.02739549e-02,  2.11188616e-03,\n          -6.10770192e-04, -5.56671728e-24, -6.40934110e-02,\n          -1.31783718e-02, -2.28130887e-03,  5.00471433e-22,\n           3.36557925e-22, -3.20787605e-23,  3.49989953e-03,\n          -4.92543764e-02,  3.76748867e-05,  1.30632266e-01,\n          -7.93991983e-03,  2.97712218e-21, -7.88172781e-02,\n           2.35449553e-01, -3.67016830e-02,  8.73321109e-03,\n           1.81755088e-02, -2.11140886e-02, -2.69638840e-04,\n          -1.74672827e-02,  4.47330077e-22, -2.40451634e-01,\n          -5.01810275e-02, -4.72277328e-02],\n         [-1.04653709e-01, -1.88790187e-01,  1.32584393e-01,\n          -3.44403232e-21, -9.95445400e-02, -2.46050321e-02,\n           3.44869941e-02,  1.30765029e-22, -1.38163105e-01,\n          -1.56216742e-02,  1.96185876e-02,  4.26046382e-22,\n           8.40068050e-22,  2.60992725e-22, -2.25787237e-02,\n          -7.37373978e-02,  5.31116675e-05,  1.84358343e-01,\n          -1.81202944e-02, -1.99627843e-21, -8.53624195e-03,\n          -1.85473576e-01, -3.98777761e-02,  1.05198614e-01,\n          -5.87904884e-04, -1.50232846e-02, -3.64173728e-04,\n           3.93330678e-02,  4.42674070e-24,  1.01220541e-01,\n          -7.80731887e-02,  1.24809071e-02],\n         [-4.09753546e-02, -7.07215592e-02,  1.45669868e-02,\n          -4.13883485e-22,  5.19662499e-02, -1.30992876e-02,\n           3.46596539e-03,  2.17046432e-22, -5.92745282e-02,\n          -7.63426954e-03,  4.46631853e-03,  4.66122182e-22,\n           5.14112390e-22, -2.94116426e-22, -2.83604721e-03,\n          -1.69742145e-02,  2.87256735e-05,  6.90025613e-02,\n           6.25104606e-02,  4.28518685e-22,  3.87471542e-02,\n          -3.67677957e-02, -3.23011987e-02, -4.83861901e-02,\n           1.23156421e-02, -5.57984132e-03, -6.53976866e-04,\n          -1.92511864e-02, -2.09685047e-22,  1.19186290e-01,\n          -2.52912678e-02,  2.02078857e-02]]]], dtype=float32)>)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-369c7ba56f62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mannealer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                validation_data=(X_test, Y_test))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1202\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1426\u001b[0m                     filepath, overwrite=True, options=self._options)\n\u001b[1;32m   1427\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1428\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1429\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2085\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 2087\u001b[0;31m                     signatures, options, save_traces)\n\u001b[0m\u001b[1;32m   2088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2089\u001b[0m   def save_weights(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    145\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m    146\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[0;32m--> 147\u001b[0;31m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[1;32m    148\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSharedObjectSavingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mmodel_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_metadata\u001b[0;34m(model, include_optimizer, require_config)\u001b[0m\n\u001b[1;32m    147\u001b[0m   \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequire_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_network_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mget_network_config\u001b[0;34m(network, serialize_layer_fn)\u001b[0m\n\u001b[1;32m   1345\u001b[0m           \u001b[0;31m# The node is relevant to the model:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;31m# add to filtered_inbound_nodes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m           \u001b[0mnode_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_make_node_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_conversion_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m           \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/node.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(self, make_node_key, node_conversion_map)\u001b[0m\n\u001b[1;32m    190\u001b[0m                       \u001b[0;34m' was passed non-JSON-serializable arguments. '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                       \u001b[0;34m'Arguments had types: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                       \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwarg_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. They cannot be serialized out '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m                       'when saving the model.')\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Layer tf.nn.convolution was passed non-JSON-serializable arguments. Arguments had types: {'filters': <class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>, 'strides': [<class 'int'>, <class 'int'>], 'padding': <class 'str'>, 'dilations': [<class 'int'>, <class 'int'>], 'data_format': <class 'str'>, 'name': <class 'str'>}. They cannot be serialized out when saving the model."
     ]
    }
   ],
   "source": [
    "model = build_mobilenet()\n",
    "annealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\n",
    "checkpoint = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/mobilenetv23005_best.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=360, \n",
    "                        width_shift_range=0.2, \n",
    "                        height_shift_range=0.2,\n",
    "                        zoom_range=0.2, \n",
    "                        horizontal_flip=True, \n",
    "                        vertical_flip=True) \n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "hist = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n",
    "               steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n",
    "               epochs=EPOCHS,\n",
    "               verbose=2,\n",
    "               callbacks=[annealer, checkpoint],\n",
    "               validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2170,
     "status": "ok",
     "timestamp": 1621423780586,
     "user": {
      "displayName": "KLRS Biomedical",
      "photoUrl": "",
      "userId": "13462190752636494514"
     },
     "user_tz": -330
    },
    "id": "rL-uJH_eIGcr",
    "outputId": "c23276d2-fe68-43fb-8174-c2da09662024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 45ms/step - loss: 0.1446 - accuracy: 0.9477\n",
      "*************************\n",
      "Loss: 0.14461275935173035, Accuracy:0.9476861357688904\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_acc = model.evaluate(X_test, Y_test)\n",
    "print(\"*************************\")\n",
    "print('Loss: {}, Accuracy:{}'.format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MN7jpUqKx30"
   },
   "source": [
    "Predicting the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "executionInfo": {
     "elapsed": 2254,
     "status": "ok",
     "timestamp": 1621423808513,
     "user": {
      "displayName": "KLRS Biomedical",
      "photoUrl": "",
      "userId": "13462190752636494514"
     },
     "user_tz": -330
    },
    "id": "cCDHPc3CIM0r",
    "outputId": "76ca689a-3c4d-4734-f0f1-7b1ecd503785"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_predict = model.predict(X_test)\n",
    "Y_predict = np.argmax(Y_predict, axis= 1)\n",
    "Y_true = np.argmax(Y_test, axis=1)\n",
    "\n",
    "cm = confusion_matrix(Y_true, Y_predict)\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "ax= sns.heatmap(cm, cmap=plt.cm.Blues, annot=True,fmt='d',annot_kws={\"size\": 25},cbar=False, square=True, xticklabels=type_of_disease,yticklabels=type_of_disease)\n",
    "ax.set_ylabel('Actual', fontsize=30)\n",
    "ax.set_xlabel('Predicted', fontsize=30)\n",
    "plt.savefig('Confusion matrix_mobilenet.svg', format='svg', dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cB89PeHBK4Rl"
   },
   "source": [
    "Accuracy and Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "executionInfo": {
     "elapsed": 2050,
     "status": "ok",
     "timestamp": 1621423833777,
     "user": {
      "displayName": "KLRS Biomedical",
      "photoUrl": "",
      "userId": "13462190752636494514"
     },
     "user_tz": -330
    },
    "id": "1r1GFoywIY-b",
    "outputId": "61554013-18a0-42d9-f067-f7dbae543148"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.xlim(0,75)\n",
    "plt.ylim(0,1)\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train','test'], loc='lower right')\n",
    "plt.savefig('Accuracy plot_mobilenet.svg', format='svg', dpi=1200)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.xlim(0,75)\n",
    "plt.ylim(0,5)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train','test'], loc='upper right')\n",
    "plt.savefig('Model loss plot_mobilenet.svg', format='svg', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9Dd9iQwGKdz"
   },
   "outputs": [],
   "source": [
    "def confusion_metrics (conf_matrix):\n",
    "\n",
    "    TP = conf_matrix[1][1]\n",
    "    TN = conf_matrix[0][0]\n",
    "    FP = conf_matrix[0][1]\n",
    "    FN = conf_matrix[1][0]\n",
    "    print('True Positives:', TP)\n",
    "    print('True Negatives:', TN)\n",
    "    print('False Positives:', FP)\n",
    "    print('False Negatives:', FN)\n",
    "    \n",
    "    #accuracy\n",
    "    conf_accuracy = (float (TP+TN) / float(TP + TN + FP + FN))\n",
    "    \n",
    "    #mis-classification\n",
    "    conf_misclassification = 1- conf_accuracy\n",
    "    \n",
    "    #sensitivity\n",
    "    conf_sensitivity = (TP / float(TP + FN))\n",
    "\n",
    "    #specificity\n",
    "    conf_specificity = (TN / float(TN + FP))\n",
    "    \n",
    "    #precision\n",
    "    conf_precision = (TN / float(TN + FP))\n",
    "\n",
    "    #recall\n",
    "    conf_recall = (TN / float(TN + FP))   \n",
    "\n",
    "    #recall\n",
    "    conf_ppv = (TP / float(TP + FP))\n",
    "\n",
    "    #recall\n",
    "    conf_npv = (TN / float(TN + FN))\n",
    "\n",
    "    # f1 score\n",
    "    conf_f1 = 2 * ((conf_precision * conf_sensitivity) / (conf_precision + conf_sensitivity))\n",
    "    print('-'*50)\n",
    "\n",
    "    print(f'Accuracy: {round(conf_accuracy,2)}') \n",
    "    print(f'Mis-Classification: {round(conf_misclassification,2)}') \n",
    "    print(f'Sensitivity: {round(conf_sensitivity,2)}') \n",
    "    print(f'Specificity: {round(conf_specificity,2)}') \n",
    "    print(f'Precision: {round(conf_precision,2)}')\n",
    "    print(f'Recall: {round(conf_recall,2)}')\n",
    "    print(f'Positive predictive Value: {round(conf_ppv,2)}')\n",
    "    print(f'Negative predictive Value: {round(conf_npv,2)}')\n",
    "    print(f'f1 Score: {round(conf_f1,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2190,
     "status": "ok",
     "timestamp": 1621423912950,
     "user": {
      "displayName": "KLRS Biomedical",
      "photoUrl": "",
      "userId": "13462190752636494514"
     },
     "user_tz": -330
    },
    "id": "cZgvb1fhp7uH",
    "outputId": "f07de2cb-525d-4692-967a-7cb9588a9b8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 220\n",
      "True Negatives: 251\n",
      "False Positives: 23\n",
      "False Negatives: 3\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.95\n",
      "Mis-Classification: 0.05\n",
      "Sensitivity: 0.99\n",
      "Specificity: 0.92\n",
      "Precision: 0.92\n",
      "Recall: 0.92\n",
      "Positive predictive Value: 0.91\n",
      "Negative predictive Value: 0.99\n",
      "f1 Score: 0.95\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "metrics = confusion_metrics(cm)\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOA21dguJ8ZLOS2sMDMkRXW",
   "collapsed_sections": [],
   "mount_file_id": "1mGaNoRLrPb6tdkJbZoNedZc0uDMwWA5l",
   "name": "MobileNet_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
